{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flying-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chief-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuing-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radical-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defensive-sucking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43824, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjusted-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43824 entries, 0 to 43823\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   No      43824 non-null  int64  \n",
      " 1   year    43824 non-null  int64  \n",
      " 2   month   43824 non-null  int64  \n",
      " 3   day     43824 non-null  int64  \n",
      " 4   hour    43824 non-null  int64  \n",
      " 5   pm2.5   41757 non-null  float64\n",
      " 6   DEWP    43824 non-null  int64  \n",
      " 7   TEMP    43824 non-null  float64\n",
      " 8   PRES    43824 non-null  float64\n",
      " 9   cbwd    43824 non-null  object \n",
      " 10  Iws     43824 non-null  float64\n",
      " 11  Is      43824 non-null  int64  \n",
      " 12  Ir      43824 non-null  int64  \n",
      "dtypes: float64(4), int64(8), object(1)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "present-turning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>6.523549</td>\n",
       "      <td>15.727820</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>98.613215</td>\n",
       "      <td>1.817246</td>\n",
       "      <td>12.448521</td>\n",
       "      <td>1016.447654</td>\n",
       "      <td>23.889140</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.194916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12651.043435</td>\n",
       "      <td>1.413842</td>\n",
       "      <td>3.448572</td>\n",
       "      <td>8.799425</td>\n",
       "      <td>6.922266</td>\n",
       "      <td>92.050387</td>\n",
       "      <td>14.433440</td>\n",
       "      <td>12.198613</td>\n",
       "      <td>10.268698</td>\n",
       "      <td>50.010635</td>\n",
       "      <td>0.760375</td>\n",
       "      <td>1.415867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10956.750000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32868.250000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>585.600000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 No          year         month           day          hour  \\\n",
       "count  43824.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean   21912.500000   2012.000000      6.523549     15.727820     11.500000   \n",
       "std    12651.043435      1.413842      3.448572      8.799425      6.922266   \n",
       "min        1.000000   2010.000000      1.000000      1.000000      0.000000   \n",
       "25%    10956.750000   2011.000000      4.000000      8.000000      5.750000   \n",
       "50%    21912.500000   2012.000000      7.000000     16.000000     11.500000   \n",
       "75%    32868.250000   2013.000000     10.000000     23.000000     17.250000   \n",
       "max    43824.000000   2014.000000     12.000000     31.000000     23.000000   \n",
       "\n",
       "              pm2.5          DEWP          TEMP          PRES           Iws  \\\n",
       "count  41757.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean      98.613215      1.817246     12.448521   1016.447654     23.889140   \n",
       "std       92.050387     14.433440     12.198613     10.268698     50.010635   \n",
       "min        0.000000    -40.000000    -19.000000    991.000000      0.450000   \n",
       "25%       29.000000    -10.000000      2.000000   1008.000000      1.790000   \n",
       "50%       72.000000      2.000000     14.000000   1016.000000      5.370000   \n",
       "75%      137.000000     15.000000     23.000000   1025.000000     21.910000   \n",
       "max      994.000000     28.000000     42.000000   1046.000000    585.600000   \n",
       "\n",
       "                 Is            Ir  \n",
       "count  43824.000000  43824.000000  \n",
       "mean       0.052734      0.194916  \n",
       "std        0.760375      1.415867  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       27.000000     36.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "average-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw/pollution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "anticipated-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "collected-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop('No', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "black-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "several-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eight-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "involved-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['year', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "healthy-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "looking-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "devoted-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['month', 'day', 'hour', 'cbwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "current-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "returning-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.DataFrame(ohe.fit_transform(df_cleaned[cat_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "diverse-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat.columns = ohe.get_feature_names(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "exempt-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop(cat_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "parental-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df_cleaned, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "premium-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "confidential-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sets_by_time(df, target_col, test_ratio=0.2):\n",
    "    \"\"\"Split sets by indexes for an ordered dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    target_col : str\n",
    "        Name of the target column\n",
    "    test_ratio : float\n",
    "        Ratio used for the validation and testing sets (default: 0.2)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Array\n",
    "        Features for the training set\n",
    "    Numpy Array\n",
    "        Target for the training set\n",
    "    Numpy Array\n",
    "        Features for the validation set\n",
    "    Numpy Array\n",
    "        Target for the validation set\n",
    "    Numpy Array\n",
    "        Features for the testing set\n",
    "    Numpy Array\n",
    "        Target for the testing set\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    target = df_copy.pop(target_col)\n",
    "    cutoff = int(len(target) / 5)\n",
    "    \n",
    "    X_train, y_train = subset_x_y(target=target, features=df_copy, start_index=0, end_index=-cutoff*2)\n",
    "    X_val, y_val     = subset_x_y(target=target, features=df_copy, start_index=-cutoff*2, end_index=-cutoff)\n",
    "    X_test, y_test   = subset_x_y(target=target, features=df_copy, start_index=-cutoff, end_index=len(target))\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "driving-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sets(X_train=None, y_train=None, X_val=None, y_val=None, X_test=None, y_test=None, path='../data/processed/'):\n",
    "    \"\"\"Save the different sets locally\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: Numpy Array\n",
    "        Features for the training set\n",
    "    y_train: Numpy Array\n",
    "        Target for the training set\n",
    "    X_val: Numpy Array\n",
    "        Features for the validation set\n",
    "    y_val: Numpy Array\n",
    "        Target for the validation set\n",
    "    X_test: Numpy Array\n",
    "        Features for the testing set\n",
    "    y_test: Numpy Array\n",
    "        Target for the testing set\n",
    "    path : str\n",
    "        Path to the folder where the sets will be saved (default: '../data/processed/')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    if X_train is not None:\n",
    "      np.save(f'{path}X_train', X_train)\n",
    "    if X_val is not None:\n",
    "      np.save(f'{path}X_val',   X_val)\n",
    "    if X_test is not None:\n",
    "      np.save(f'{path}X_test',  X_test)\n",
    "    if y_train is not None:\n",
    "      np.save(f'{path}y_train', y_train)\n",
    "    if y_val is not None:\n",
    "      np.save(f'{path}y_val',   y_val)\n",
    "    if y_test is not None:\n",
    "      np.save(f'{path}y_test',  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "modern-hamilton",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subset_x_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-fcb008d29254>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### use functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_sets_by_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pm2.5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-2547fbaa3d0c>\u001b[0m in \u001b[0;36msplit_sets_by_time\u001b[1;34m(df, target_col, test_ratio)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mcutoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubset_x_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0msubset_x_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0msubset_x_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subset_x_y' is not defined"
     ]
    }
   ],
   "source": [
    "### use functions\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_by_time(X, target_col='pm2.5', test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pacific-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_target = X.pop('pm2.5')\n",
    "\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, train_data_target, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rural-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NullModel:\n",
    "    \"\"\"\n",
    "    Class used as baseline model for both regression and classification\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_type : str\n",
    "        Type of ML problem (default regression)\n",
    "    y : Numpy Array-like\n",
    "        Target variable\n",
    "    pred_value : Float\n",
    "        Value to be used for prediction\n",
    "    preds : Numpy Array\n",
    "        Predicted array\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(y)\n",
    "        Store the input target variable and calculate the predicted value to be used based on the problem type\n",
    "    predict(y)\n",
    "        Generate the predictions\n",
    "    fit_predict(y)\n",
    "        Perform a fit followed by predict\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    def __init__(self, target_type: str = \"regression\"):\n",
    "        self.target_type = target_type\n",
    "        self.y = None\n",
    "        self.pred_value = None\n",
    "        self.preds = None\n",
    "        \n",
    "    def fit(self, y):\n",
    "        self.y = y\n",
    "        if self.target_type == \"regression\":\n",
    "            self.pred_value = y.mean()\n",
    "        else:\n",
    "            from scipy.stats import mode\n",
    "            self.pred_value = mode(y)[0][0]\n",
    "    \n",
    "    def predict(self, y):\n",
    "        self.preds = np.full((len(y), 1), self.pred_value)\n",
    "        return self.preds\n",
    "    \n",
    "    def fit_predict(self, y):\n",
    "        self.fit(y)\n",
    "        return self.predict(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "foreign-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_perf(y_preds, y_actuals, set_name=None, average='binary'):\n",
    "    \"\"\"Print the Accuracy and F1 score for the provided data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_preds : Numpy Array\n",
    "        Predicted target\n",
    "    y_actuals : Numpy Array\n",
    "        Actual target\n",
    "    set_name : str\n",
    "        Name of the set to be printed\n",
    "    average : str\n",
    "        Parameter  for F1-score averaging\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    print(f\"Accuracy {set_name}: {accuracy_score(y_actuals, y_preds)}\")\n",
    "    print(f\"F1 {set_name}: {f1_score(y_actuals, y_preds, average=average)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "textile-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_reg_perf(y_preds, y_actuals, set_name=None):\n",
    "    \"\"\"Print the RMSE and MAE for the provided data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_preds : Numpy Array\n",
    "        Predicted target\n",
    "    y_actuals : Numpy Array\n",
    "        Actual target\n",
    "    set_name : str\n",
    "        Name of the set to be printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    \n",
    "    print(f\"RMSE {set_name}: {mse(y_actuals, y_preds, squared=False)}\")\n",
    "    print(f\"MAE {set_name}: {mae(y_actuals, y_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "permanent-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = NullModel()\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "immune-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 91.97430455719193\n",
      "MAE Training: 68.83353279913013\n"
     ]
    }
   ],
   "source": [
    "print_reg_perf(y_base, y_train, set_name='Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ignored-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sticky-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchRegression, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(num_features, 128)\n",
    "        self.layer_out = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)))\n",
    "        x = self.layer_out(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aquatic-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchRegression(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "generous-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "great-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PytorchRegression(\n",
       "  (layer_1): Linear(in_features=78, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "casual-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "### awkward fix\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "timely-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchRegression(\n",
      "  (layer_1): Linear(in_features=78, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "prepared-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "golden-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "equipped-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "palestinian-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "encouraging-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Model\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "biblical-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adopted-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, collate_fn=None):\n",
    "    \"\"\"Train a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class)\n",
    "        \n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), np.sqrt(train_loss / len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "approved-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regression(test_data, model, criterion, batch_size, device, collate_fn=None):\n",
    "    \"\"\"Calculate performance of a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class)\n",
    "            \n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    return test_loss / len(test_data), np.sqrt(test_loss / len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "compatible-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "worthy-custom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([13])) that is different to the input size (torch.Size([13, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\tLoss: 335.1671\t|\tRMSE: 18.3\n",
      "\t(valid)\tLoss: 272.4057\t|\tRMSE: 16.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([24])) that is different to the input size (torch.Size([24, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\t(train)\tLoss: 267.6104\t|\tRMSE: 16.4\n",
      "\t(valid)\tLoss: 272.4510\t|\tRMSE: 16.5\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 267.4702\t|\tRMSE: 16.4\n",
      "\t(valid)\tLoss: 271.8549\t|\tRMSE: 16.5\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 267.3733\t|\tRMSE: 16.4\n",
      "\t(valid)\tLoss: 272.1152\t|\tRMSE: 16.5\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 267.3358\t|\tRMSE: 16.4\n",
      "\t(valid)\tLoss: 271.8675\t|\tRMSE: 16.5\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_rmse = train_regression(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_rmse = test_regression(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tRMSE: {train_rmse:.1f}')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tRMSE: {valid_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "extreme-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../models/pytorch_reg_pm2_5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "confused-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 265.7728\t|\tRMSE: 16.3\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_rmse = test_regression(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tRMSE: {test_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-charter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
