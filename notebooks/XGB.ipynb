{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "separate-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "\n",
    "# File management\n",
    "import os\n",
    "\n",
    "# Data/numeric manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Modelling & Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concrete-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in data\n",
    "\n",
    "beer_dat = pd.read_csv(r\"C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\Projects\\advdsi_at2\\data\\raw\\beer_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cognitive-tumor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of beer styles: 5840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10325,  1075,   163, ..., 12566,  7337,  6102], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of beer styles: {}\".format(len(beer_dat.brewery_id.unique())))\n",
    "beer_dat.brewery_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "viral-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide up data\n",
    "num_cols = ['review_aroma','review_appearance','review_palate','review_taste']\n",
    "\n",
    "cat_cols = ['brewery_id']\n",
    "key_feat = ['brewery_id','review_aroma','review_appearance','review_palate','review_taste','beer_style']\n",
    "\n",
    "df_cleaned = beer_dat[key_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consecutive-spencer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-1a50bd7a9b68>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])\n",
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:4305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:4305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#Instantiate SC\n",
    "sc = StandardScaler()\n",
    "#Scale numerics\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])\n",
    "\n",
    "\n",
    "#scale Cat\n",
    "X_cat = df_cleaned[cat_cols].astype('category')\n",
    "df_cleaned.drop(cat_cols, axis=1, inplace=True)\n",
    "ode = OrdinalEncoder()\n",
    "X_cat_y = pd.DataFrame(ode.fit_transform(df_cleaned[y_cat_cols]))\n",
    "X_cat_y.columns = y_cat_cols\n",
    "X_cat_y = X_cat_y.astype(int)\n",
    "df_cleaned.drop(y_cat_cols, axis=1, inplace=True)\n",
    "X_cat_cols = pd.concat([X_cat, X_cat_y ], axis=1)\n",
    "\n",
    "#recombine as X\n",
    "X = pd.concat([df_cleaned, X_cat_cols ], axis=1)\n",
    "\n",
    "X = X.drop(columns=['brewery_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "promising-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\Projects\\advdsi_at2\\src\\data\")\n",
    "from sets import subset_x_y, split_sets_by_time, save_sets, split_sets_random\n",
    "os.chdir(r\"C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\Projects\\advdsi_at2\\notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "closed-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train test split, change to numpy\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(X, target_col='beer_style', test_ratio=0.2, to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oriental-stewart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
      "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Train RF Model\n",
    "\n",
    "xgb = XGBClassifier(eval_metric='auc')\n",
    "xgb.fit(X_train, y_train)\n",
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shared-genesis",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`data` and `annot` must have same shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-50ea456ac636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34mf\"{v1}\\n{v2}\\n{v3}\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv3\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgroup_counts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgroup_percentages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Blues'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \"\"\"\n\u001b[0;32m    534\u001b[0m     \u001b[1;31m# Initialize the plotter object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0m\u001b[0;32m    536\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                           yticklabels, mask)\n",
      "\u001b[1;32mc:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mannot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"`data` and `annot` must have same shape.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mannot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `data` and `annot` must have same shape."
     ]
    }
   ],
   "source": [
    "### Evaluations\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# print evaluation scores\n",
    "print(f'{np.sum(y_test_pred)} out of {len(y_test_pred)} or {int(round(np.sum(y_test_pred)/len(y_test_pred)*100,0))}% of players are predicted to be 5+ Yrs')\n",
    "print(f'-----------\\nRecall: {round(recall_score(y_test, y_test_pred), 4)}')\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_test_pred), 4)}')\n",
    "print(f'F1: {round(f1_score(y_test, y_test_pred), 4)}')\n",
    "print(f'-----------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "designed-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Angus\\\\Documents\\\\UTS MDSI\\\\Advanced DSI\\\\Projects\\\\advdsi_at2\\\\models\\\\XGB_4feat.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "from joblib import dump  \n",
    "\n",
    "dump(xgb, r'C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\Projects\\advdsi_at2\\models\\XGB_4feat.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minor-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "global-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1521\n",
      "           1       0.14      0.63      0.23      6085\n",
      "           2       0.04      0.00      0.00      9288\n",
      "           3       0.00      0.00      0.00      1887\n",
      "           4       0.00      0.00      0.00      5390\n",
      "           5       0.00      0.00      0.00      2394\n",
      "           6       0.00      0.00      0.00      2594\n",
      "           7       0.03      0.00      0.00      5066\n",
      "           8       0.00      0.00      0.00       296\n",
      "           9       0.11      0.22      0.15     17159\n",
      "          10       0.00      0.00      0.00      1109\n",
      "          11       0.08      0.03      0.04     10187\n",
      "          12       0.08      0.71      0.15     23356\n",
      "          13       0.00      0.00      0.00       759\n",
      "          14       0.06      0.09      0.07     12479\n",
      "          15       0.00      0.00      0.00      1871\n",
      "          16       0.05      0.00      0.00      4900\n",
      "          17       0.06      0.01      0.02     10097\n",
      "          18       0.03      0.00      0.00      4966\n",
      "          19       0.09      0.00      0.00      6335\n",
      "          20       0.02      0.00      0.00      3494\n",
      "          21       0.00      0.00      0.00      2322\n",
      "          22       0.00      0.00      0.00      1278\n",
      "          23       0.00      0.00      0.00      2428\n",
      "          24       0.00      0.00      0.00      3954\n",
      "          25       0.00      0.00      0.00      7511\n",
      "          26       0.02      0.00      0.00      6181\n",
      "          27       0.00      0.00      0.00       712\n",
      "          28       0.00      0.00      0.00       211\n",
      "          29       0.00      0.00      0.00      1340\n",
      "          30       0.00      0.00      0.00       459\n",
      "          31       0.05      0.00      0.00      2323\n",
      "          32       0.00      0.00      0.00       207\n",
      "          33       0.00      0.00      0.00       809\n",
      "          34       0.08      0.00      0.01       496\n",
      "          35       0.00      0.00      0.00      1052\n",
      "          36       0.00      0.00      0.00      2484\n",
      "          37       0.04      0.00      0.00      4380\n",
      "          38       0.00      0.00      0.00       928\n",
      "          39       0.00      0.00      0.00      4036\n",
      "          40       0.00      0.00      0.00      1426\n",
      "          41       0.00      0.00      0.00       506\n",
      "          42       0.25      0.00      0.00      2798\n",
      "          43       0.00      0.00      0.00      1783\n",
      "          44       0.03      0.00      0.00      3870\n",
      "          45       0.00      0.00      0.00       482\n",
      "          46       0.00      0.00      0.00      3218\n",
      "          47       0.02      0.00      0.00      4631\n",
      "          48       0.00      0.00      0.00       135\n",
      "          49       0.11      0.00      0.00      2225\n",
      "          50       0.00      0.00      0.00       605\n",
      "          51       0.00      0.00      0.00       982\n",
      "          52       0.00      0.00      0.00       916\n",
      "          53       0.07      0.03      0.04      3673\n",
      "          54       0.00      0.00      0.00       542\n",
      "          55       0.00      0.00      0.00      3539\n",
      "          56       0.00      0.00      0.00       117\n",
      "          57       0.00      0.00      0.00       944\n",
      "          58       0.00      0.00      0.00      1332\n",
      "          59       0.00      0.00      0.00      1185\n",
      "          60       0.08      0.09      0.08      6710\n",
      "          61       0.00      0.00      0.00      4416\n",
      "          62       0.00      0.00      0.00       119\n",
      "          63       0.00      0.00      0.00      1206\n",
      "          64       0.00      0.00      0.00        46\n",
      "          65       0.02      0.00      0.00      5675\n",
      "          66       0.00      0.00      0.00      2081\n",
      "          67       0.09      0.02      0.04      2537\n",
      "          68       0.00      0.00      0.00      1572\n",
      "          69       0.00      0.00      0.00       308\n",
      "          70       0.00      0.00      0.00       525\n",
      "          71       0.00      0.00      0.00       426\n",
      "          72       0.00      0.00      0.00        63\n",
      "          73       0.00      0.00      0.00      1678\n",
      "          74       0.00      0.00      0.00      2152\n",
      "          75       0.00      0.00      0.00       227\n",
      "          76       0.32      0.25      0.28      2759\n",
      "          77       0.00      0.00      0.00       222\n",
      "          78       0.00      0.00      0.00      2087\n",
      "          79       0.05      0.00      0.00      2623\n",
      "          80       0.00      0.00      0.00      1566\n",
      "          81       0.00      0.00      0.00      1600\n",
      "          82       0.00      0.00      0.00      4777\n",
      "          83       0.00      0.00      0.00      3646\n",
      "          84       0.00      0.00      0.00      2927\n",
      "          85       0.03      0.00      0.00      3122\n",
      "          86       0.00      0.00      0.00      3737\n",
      "          87       0.00      0.00      0.00       817\n",
      "          88       0.00      0.00      0.00       101\n",
      "          89       0.11      0.16      0.13     10792\n",
      "          90       0.12      0.00      0.00      2054\n",
      "          91       0.00      0.00      0.00       198\n",
      "          92       0.05      0.00      0.00      6327\n",
      "          93       0.00      0.00      0.00      1956\n",
      "          94       0.00      0.00      0.00      3460\n",
      "          95       0.00      0.00      0.00      1827\n",
      "          96       0.00      0.00      0.00       557\n",
      "          97       0.00      0.00      0.00       556\n",
      "          98       0.03      0.00      0.00      6074\n",
      "          99       0.00      0.00      0.00      1865\n",
      "         100       0.00      0.00      0.00      1922\n",
      "         101       0.00      0.00      0.00       731\n",
      "         102       0.00      0.00      0.00      4130\n",
      "         103       0.04      0.00      0.00      5896\n",
      "\n",
      "    accuracy                           0.09    317323\n",
      "   macro avg       0.02      0.02      0.01    317323\n",
      "weighted avg       0.05      0.09      0.04    317323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "appreciated-optimization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  129,    3, ...,    0,    0,    1],\n",
       "       [   0, 3834,   33, ...,    0,    0,    5],\n",
       "       [   0,  821,   21, ...,    0,    0,    8],\n",
       "       ...,\n",
       "       [   0,   20,    1, ...,    0,    0,    0],\n",
       "       [   0,  225,    5, ...,    0,    0,    3],\n",
       "       [   0,  600,   17, ...,    1,    0,   11]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-columbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
