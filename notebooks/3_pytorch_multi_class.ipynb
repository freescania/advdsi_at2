{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cultural-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "billion-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'https://raw.githubusercontent.com/aso-uts/applied_ds/master/unit3/dataset/Car%20Evaluation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aging-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bottom-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   buying_price      1728 non-null   object\n",
      " 1   maintenance_cost  1728 non-null   object\n",
      " 2   doors             1728 non-null   object\n",
      " 3   persons_capacity  1728 non-null   object\n",
      " 4   luggage_boot      1728 non-null   object\n",
      " 5   safety            1728 non-null   object\n",
      " 6   evaluation        1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minus-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw/car_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unnecessary-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "civic-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_dict = {\n",
    "    'buying_price': [['low', 'med', 'high', 'vhigh']],\n",
    "    'maintenance_cost': [['low', 'med', 'high', 'vhigh']],\n",
    "    'doors': [['2', '3', '4', '5more']],\n",
    "    'persons_capacity': [['2', '4', 'more']],\n",
    "    'luggage_boot': [['small', 'med', 'big']],\n",
    "    'safety': [['low', 'med', 'high']],\n",
    "    'evaluation': [['unacc', 'acc', 'good', 'vgood']],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "billion-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hungarian-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, cats in cats_dict.items():\n",
    "    col_encoder = OrdinalEncoder(categories=cats)\n",
    "    df_cleaned[col] = col_encoder.fit_transform(df_cleaned[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ahead-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['buying_price', 'maintenance_cost', 'doors', 'persons_capacity', 'luggage_boot', 'safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unable-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "undefined-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "extraordinary-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['evaluation'] = df_cleaned['evaluation'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "structural-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying_price  maintenance_cost     doors  persons_capacity  \\\n",
       "1723     -1.341641         -1.341641  1.341641          1.224745   \n",
       "1724     -1.341641         -1.341641  1.341641          1.224745   \n",
       "1725     -1.341641         -1.341641  1.341641          1.224745   \n",
       "1726     -1.341641         -1.341641  1.341641          1.224745   \n",
       "1727     -1.341641         -1.341641  1.341641          1.224745   \n",
       "\n",
       "      luggage_boot    safety  evaluation  \n",
       "1723      0.000000  0.000000           2  \n",
       "1724      0.000000  1.224745           3  \n",
       "1725      1.224745 -1.224745           0  \n",
       "1726      1.224745  0.000000           2  \n",
       "1727      1.224745  1.224745           3  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(df_cleaned.copy())\n",
    "df_cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "buried-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_target = X.pop('evaluation')\n",
    "\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, train_data_target, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "educational-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "black-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "chubby-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "excited-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NullModel:\n",
    "    \"\"\"\n",
    "    Class used as baseline model for both regression and classification\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_type : str\n",
    "        Type of ML problem (default regression)\n",
    "    y : Numpy Array-like\n",
    "        Target variable\n",
    "    pred_value : Float\n",
    "        Value to be used for prediction\n",
    "    preds : Numpy Array\n",
    "        Predicted array\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(y)\n",
    "        Store the input target variable and calculate the predicted value to be used based on the problem type\n",
    "    predict(y)\n",
    "        Generate the predictions\n",
    "    fit_predict(y)\n",
    "        Perform a fit followed by predict\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    def __init__(self, target_type: str = \"regression\"):\n",
    "        self.target_type = target_type\n",
    "        self.y = None\n",
    "        self.pred_value = None\n",
    "        self.preds = None\n",
    "        \n",
    "    def fit(self, y):\n",
    "        self.y = y\n",
    "        if self.target_type == \"regression\":\n",
    "            self.pred_value = y.mean()\n",
    "        else:\n",
    "            from scipy.stats import mode\n",
    "            self.pred_value = mode(y)[0][0]\n",
    "    \n",
    "    def predict(self, y):\n",
    "        self.preds = np.full((len(y), 1), self.pred_value)\n",
    "        return self.preds\n",
    "    \n",
    "    def fit_predict(self, y):\n",
    "        self.fit(y)\n",
    "        return self.predict(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "global-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = NullModel(target_type='classification')\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "unsigned-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_perf(y_preds, y_actuals, set_name=None, average='binary'):\n",
    "    \"\"\"Print the Accuracy and F1 score for the provided data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_preds : Numpy Array\n",
    "        Predicted target\n",
    "    y_actuals : Numpy Array\n",
    "        Actual target\n",
    "    set_name : str\n",
    "        Name of the set to be printed\n",
    "    average : str\n",
    "        Parameter  for F1-score averaging\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    print(f\"Accuracy {set_name}: {accuracy_score(y_actuals, y_preds)}\")\n",
    "    print(f\"F1 {set_name}: {f1_score(y_actuals, y_preds, average=average)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "lyric-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.7005789909015715\n",
      "F1 Training: 0.5772280207136489\n"
     ]
    }
   ],
   "source": [
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "english-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchMultiClass(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchMultiClass, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 32)\n",
    "        self.layer_out = nn.Linear(32, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)), training=self.training)\n",
    "        x = self.layer_out(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "australian-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchMultiClass(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "disciplinary-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "### awkward fix\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "australian-perception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer_out): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "junior-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchMultiClass(\n",
      "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
      "  (layer_out): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "alike-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "worldwide-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bibliographic-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classification(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, generate_batch=None):\n",
    "    \"\"\"Train a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class.long())\n",
    "\n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate global accuracy\n",
    "        train_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), train_acc / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "convertible-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification(test_data, model, criterion, batch_size, device, generate_batch=None):\n",
    "    \"\"\"Calculate performance of a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class.long())\n",
    "\n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate global accuracy\n",
    "            test_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    return test_loss / len(test_data), test_acc / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cathedral-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hungarian-andorra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.0316\t|\tAcc: 73.7%\n",
      "\t(valid)\t|\tLoss: 0.0319\t|\tAcc: 79.9%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.0300\t|\tAcc: 79.0%\n",
      "\t(valid)\t|\tLoss: 0.0319\t|\tAcc: 80.3%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.0294\t|\tAcc: 80.5%\n",
      "\t(valid)\t|\tLoss: 0.0314\t|\tAcc: 82.2%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.0292\t|\tAcc: 81.5%\n",
      "\t(valid)\t|\tLoss: 0.0310\t|\tAcc: 83.4%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 83.0%\n",
      "\t(valid)\t|\tLoss: 0.0310\t|\tAcc: 83.8%\n",
      "Epoch: 5\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 81.0%\n",
      "\t(valid)\t|\tLoss: 0.0303\t|\tAcc: 86.1%\n",
      "Epoch: 6\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 81.8%\n",
      "\t(valid)\t|\tLoss: 0.0316\t|\tAcc: 81.5%\n",
      "Epoch: 7\n",
      "\t(train)\t|\tLoss: 0.0289\t|\tAcc: 82.4%\n",
      "\t(valid)\t|\tLoss: 0.0311\t|\tAcc: 83.0%\n",
      "Epoch: 8\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 82.1%\n",
      "\t(valid)\t|\tLoss: 0.0306\t|\tAcc: 84.9%\n",
      "Epoch: 9\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 83.9%\n",
      "\t(valid)\t|\tLoss: 0.0304\t|\tAcc: 85.3%\n",
      "Epoch: 10\n",
      "\t(train)\t|\tLoss: 0.0288\t|\tAcc: 82.5%\n",
      "\t(valid)\t|\tLoss: 0.0305\t|\tAcc: 85.3%\n",
      "Epoch: 11\n",
      "\t(train)\t|\tLoss: 0.0288\t|\tAcc: 82.7%\n",
      "\t(valid)\t|\tLoss: 0.0310\t|\tAcc: 83.4%\n",
      "Epoch: 12\n",
      "\t(train)\t|\tLoss: 0.0289\t|\tAcc: 82.2%\n",
      "\t(valid)\t|\tLoss: 0.0299\t|\tAcc: 86.9%\n",
      "Epoch: 13\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 83.5%\n",
      "\t(valid)\t|\tLoss: 0.0295\t|\tAcc: 88.4%\n",
      "Epoch: 14\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 85.9%\n",
      "\t(valid)\t|\tLoss: 0.0304\t|\tAcc: 85.3%\n",
      "Epoch: 15\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 84.3%\n",
      "\t(valid)\t|\tLoss: 0.0303\t|\tAcc: 85.7%\n",
      "Epoch: 16\n",
      "\t(train)\t|\tLoss: 0.0288\t|\tAcc: 82.5%\n",
      "\t(valid)\t|\tLoss: 0.0302\t|\tAcc: 86.1%\n",
      "Epoch: 17\n",
      "\t(train)\t|\tLoss: 0.0281\t|\tAcc: 85.1%\n",
      "\t(valid)\t|\tLoss: 0.0311\t|\tAcc: 83.0%\n",
      "Epoch: 18\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 84.3%\n",
      "\t(valid)\t|\tLoss: 0.0301\t|\tAcc: 86.5%\n",
      "Epoch: 19\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 84.4%\n",
      "\t(valid)\t|\tLoss: 0.0301\t|\tAcc: 86.5%\n",
      "Epoch: 20\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 83.6%\n",
      "\t(valid)\t|\tLoss: 0.0298\t|\tAcc: 87.6%\n",
      "Epoch: 21\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 84.6%\n",
      "\t(valid)\t|\tLoss: 0.0299\t|\tAcc: 86.9%\n",
      "Epoch: 22\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 85.4%\n",
      "\t(valid)\t|\tLoss: 0.0293\t|\tAcc: 88.8%\n",
      "Epoch: 23\n",
      "\t(train)\t|\tLoss: 0.0281\t|\tAcc: 84.9%\n",
      "\t(valid)\t|\tLoss: 0.0293\t|\tAcc: 88.8%\n",
      "Epoch: 24\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 84.7%\n",
      "\t(valid)\t|\tLoss: 0.0293\t|\tAcc: 89.2%\n",
      "Epoch: 25\n",
      "\t(train)\t|\tLoss: 0.0281\t|\tAcc: 85.1%\n",
      "\t(valid)\t|\tLoss: 0.0302\t|\tAcc: 86.1%\n",
      "Epoch: 26\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 83.9%\n",
      "\t(valid)\t|\tLoss: 0.0299\t|\tAcc: 87.3%\n",
      "Epoch: 27\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 84.0%\n",
      "\t(valid)\t|\tLoss: 0.0306\t|\tAcc: 84.9%\n",
      "Epoch: 28\n",
      "\t(train)\t|\tLoss: 0.0281\t|\tAcc: 84.8%\n",
      "\t(valid)\t|\tLoss: 0.0303\t|\tAcc: 85.7%\n",
      "Epoch: 29\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 85.1%\n",
      "\t(valid)\t|\tLoss: 0.0295\t|\tAcc: 88.4%\n",
      "Epoch: 30\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 84.0%\n",
      "\t(valid)\t|\tLoss: 0.0297\t|\tAcc: 87.6%\n",
      "Epoch: 31\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 84.3%\n",
      "\t(valid)\t|\tLoss: 0.0296\t|\tAcc: 88.0%\n",
      "Epoch: 32\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 84.7%\n",
      "\t(valid)\t|\tLoss: 0.0302\t|\tAcc: 86.1%\n",
      "Epoch: 33\n",
      "\t(train)\t|\tLoss: 0.0286\t|\tAcc: 83.3%\n",
      "\t(valid)\t|\tLoss: 0.0309\t|\tAcc: 83.8%\n",
      "Epoch: 34\n",
      "\t(train)\t|\tLoss: 0.0286\t|\tAcc: 83.5%\n",
      "\t(valid)\t|\tLoss: 0.0312\t|\tAcc: 83.0%\n",
      "Epoch: 35\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 84.2%\n",
      "\t(valid)\t|\tLoss: 0.0307\t|\tAcc: 84.6%\n",
      "Epoch: 36\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 82.9%\n",
      "\t(valid)\t|\tLoss: 0.0303\t|\tAcc: 85.7%\n",
      "Epoch: 37\n",
      "\t(train)\t|\tLoss: 0.0289\t|\tAcc: 82.4%\n",
      "\t(valid)\t|\tLoss: 0.0313\t|\tAcc: 82.2%\n",
      "Epoch: 38\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 82.9%\n",
      "\t(valid)\t|\tLoss: 0.0310\t|\tAcc: 83.4%\n",
      "Epoch: 39\n",
      "\t(train)\t|\tLoss: 0.0289\t|\tAcc: 82.5%\n",
      "\t(valid)\t|\tLoss: 0.0307\t|\tAcc: 84.2%\n",
      "Epoch: 40\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 82.9%\n",
      "\t(valid)\t|\tLoss: 0.0326\t|\tAcc: 78.4%\n",
      "Epoch: 41\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 82.1%\n",
      "\t(valid)\t|\tLoss: 0.0304\t|\tAcc: 85.3%\n",
      "Epoch: 42\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 83.9%\n",
      "\t(valid)\t|\tLoss: 0.0301\t|\tAcc: 86.5%\n",
      "Epoch: 43\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 84.4%\n",
      "\t(valid)\t|\tLoss: 0.0301\t|\tAcc: 86.1%\n",
      "Epoch: 44\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 84.1%\n",
      "\t(valid)\t|\tLoss: 0.0303\t|\tAcc: 85.7%\n",
      "Epoch: 45\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 84.4%\n",
      "\t(valid)\t|\tLoss: 0.0303\t|\tAcc: 85.7%\n",
      "Epoch: 46\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 83.6%\n",
      "\t(valid)\t|\tLoss: 0.0304\t|\tAcc: 85.3%\n",
      "Epoch: 47\n",
      "\t(train)\t|\tLoss: 0.0291\t|\tAcc: 81.6%\n",
      "\t(valid)\t|\tLoss: 0.0320\t|\tAcc: 80.3%\n",
      "Epoch: 48\n",
      "\t(train)\t|\tLoss: 0.0291\t|\tAcc: 81.8%\n",
      "\t(valid)\t|\tLoss: 0.0322\t|\tAcc: 79.5%\n",
      "Epoch: 49\n",
      "\t(train)\t|\tLoss: 0.0292\t|\tAcc: 81.4%\n",
      "\t(valid)\t|\tLoss: 0.0310\t|\tAcc: 83.4%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "asian-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../models/pytorch_multi_car_evaluation.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "exotic-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.0307\t|\tAccuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAccuracy: {test_acc:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-parks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
